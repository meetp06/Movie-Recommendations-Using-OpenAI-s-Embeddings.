{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1097fa17-48de-4e79-87fa-2fbdd2963415",
   "metadata": {},
   "source": [
    "# Movie Recommendations Using OpenAI's Embeddings\n",
    "\n",
    "## Libraries Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001d298-f714-48da-9372-7115f7b18dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets==3.0.0 openai==1.16.2 pandas==1.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1a366-bb4f-4cbd-ba80-2aa2204f89ac",
   "metadata": {},
   "source": [
    "## Module 1\n",
    "### Task 1: Data Loading\n",
    "Load the dataset titled \"AIatMongoDB/embedded_movies\". This dataset is a collection of movie-related details that include attributes such as the title, release year, cast, plot, and more. A unique feature of this dataset is the `plot_embedding` field for each movie. These embeddings are generated using OpenAI's text-embedding-ada-002 model. But now, let's just read the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91feca1d-d1c6-4199-9479-06d33d450d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset(\"AIatMongoDB/embedded_movies\")\n",
    "dataset_df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(dataset_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a76839-b384-4262-b31e-7b410b77bf02",
   "metadata": {},
   "source": [
    "###  WRITE YOUR CODE FOR TASK 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca204b-5f6e-418b-9867-59134e84239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = dataset_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30438cd-0b51-4b4a-89aa-c37e660b9597",
   "metadata": {},
   "source": [
    "###  Inspect data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ac896-7efc-486a-9509-052495eacb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82ed411-e9ea-4906-8505-3c810ee02316",
   "metadata": {},
   "source": [
    "###  WRITE YOUR CODE FOR TASK 3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de97e3c-092d-4fcf-92db-416e629fa894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'plot' is missing\n",
    "dataset_df = dataset_df.dropna(subset=['plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e0dbf-75e6-4417-8ed6-66b4040607f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'plot_embedding' column\n",
    "dataset_df = dataset_df.drop(columns=['plot_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaea8bc-84d5-4f92-8a68-1755046a010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the cleaned dataset\n",
    "print(dataset_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7b65de-52e4-447b-b26c-728684f73a2c",
   "metadata": {},
   "source": [
    "## Task 4: Create Embeddings with OpenAI\n",
    "### Generate new embeddings using OpenAI's advanced model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1688452-6466-42a8-ad37-fcc9244125af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = \"your-api-key-here\"\n",
    "\n",
    "# Define the embedding model\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generate an embedding for the given text using OpenAI's API.\"\"\"\n",
    "    try:\n",
    "        response = openai.Embedding.create(input=text, model=EMBEDDING_MODEL)\n",
    "        return response['data'][0]['embedding']\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the embedding function to the 'plot' column\n",
    "dataset_df['plot_embedding_optimized'] = dataset_df['plot'].apply(get_embedding)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "dataset_df.to_csv('datasets.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a5eda-9f46-4e7e-8dea-1ddfafd49c50",
   "metadata": {},
   "source": [
    "## Task 5: Generating Movie Recommendations and Responses\n",
    "### Calculate similarity scores and provide recommendations based on user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73424d-bfe6-42a0-99fe-23c831b389f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to perform vector search based on embeddings\n",
    "def vector_search(query_embedding, df):\n",
    "    \"\"\"Perform vector search by calculating cosine similarity.\"\"\"\n",
    "    df['similarity'] = df['plot_embedding_optimized'].apply(\n",
    "        lambda x: np.dot(query_embedding, x) / (np.linalg.norm(query_embedding) * np.linalg.norm(x))\n",
    "    )\n",
    "    return df.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "# Function to handle user query\n",
    "def handle_user_query(query, df):\n",
    "    \"\"\"Generate recommendations based on user query.\"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\", None\n",
    "    \n",
    "    # Perform vector search\n",
    "    result_df = vector_search(query_embedding, df)\n",
    "    \n",
    "    # Extract top 5 matches\n",
    "    top_matches = result_df.head(5)\n",
    "    \n",
    "    # Format search result\n",
    "    search_result = \"\\n\".join([f\"Title: {row['title']}, Plot: {row['plot']}\" for _, row in top_matches.iterrows()])\n",
    "    \n",
    "    # Use OpenAI chat completions to generate response\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Recommend movies based on: {query}\"}]\n",
    "    )\n",
    "    return completion.choices[0].message['content'].strip(), search_result\n",
    "\n",
    "# Sample query\n",
    "query = \"What are the best action movies?\"\n",
    "\n",
    "# Generate recommendations\n",
    "response, source_information = handle_user_query(query, dataset_df)\n",
    "\n",
    "# Save results to a text file\n",
    "with open(\"response.txt\", \"w\") as file:\n",
    "    file.write(response)\n",
    "    file.write(\"\\n\\nSource Information:\\n\")\n",
    "    file.write(source_information)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
